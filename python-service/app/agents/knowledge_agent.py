from typing import Dict, Any, List, Optional
from pydantic import BaseModel, Field
import pydantic_ai
from openai import OpenAI
from pydantic_ai import Agent, RunContext
import asyncio

# Importamos el estado global y funciones de Zep
from ..state import GlobalState
from ..zep import get_zep_memory_context, search_zep_facts, search_zep_sessions, search_zep_nodes
from ..db import supabase_client

# --- Cliente Pydantic AI ---
# Usamos un cliente de OpenAI independiente para este agente
# para mantener los contextos de herramientas separados.
client = OpenAI()

# --- Funciones Auxiliares para B√∫squeda Sem√°ntica ---

async def generate_embedding(text: str) -> List[float]:
    """
    Genera un embedding para el texto usando OpenAI.
    """
    try:
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"‚ùå Error generando embedding: {e}")
        return []

async def search_knowledge_semantic(query: str, organization_id: str, limit: int = 5) -> List[Dict[str, Any]]:
    """
    Busca informaci√≥n (servicios y archivos) usando b√∫squeda sem√°ntica en la knowledge_base.
    
    Args:
        query: Consulta de b√∫squeda del usuario
        organization_id: ID de la organizaci√≥n 
        limit: N√∫mero m√°ximo de resultados
    
    Returns:
        Lista de contenido encontrado (servicios y archivos) con sus metadatos
    """
    try:
        # Generar embedding de la consulta
        query_embedding = await generate_embedding(query)
        
        if not query_embedding:
            return []
        
        # Buscar en knowledge_base usando similarity search
        # Usamos la funci√≥n match_documents de Supabase que maneja embeddings
        result = supabase_client.rpc(
            'match_documents',
            {
                'query_embedding': query_embedding,
                'match_count': limit,
                'filter': {'organization_id': organization_id}
            }
        ).execute()
        
        results_found = []
        seen_items = set()
        
        if result.data:
            for item in result.data:
                metadata = item.get('metadata', {})
                source_type = metadata.get('source_type')
                
                if source_type == 'service':
                    service_id = metadata.get('service_id')
                    # Evitar duplicados del mismo servicio
                    if service_id and service_id not in seen_items:
                        seen_items.add(service_id)
                        results_found.append({
                            'service_id': service_id,
                            'content': item.get('content', ''),
                            'similarity': item.get('similarity', 0),
                            'metadata': metadata
                        })
                        
                elif source_type == 'file':
                    # Para archivos, usamos una combinaci√≥n √∫nica de file_name + category
                    file_name = metadata.get('file_name', '')
                    category = metadata.get('category', '')
                    unique_key = f"{file_name}_{category}"
                    
                    if unique_key not in seen_items:
                        seen_items.add(unique_key)
                        results_found.append({
                            'content': item.get('content', ''),
                            'similarity': item.get('similarity', 0),
                            'metadata': metadata
                        })
        
        return results_found
        
    except Exception as e:
        print(f"‚ùå Error en b√∫squeda sem√°ntica: {e}")
        return []

async def get_service_by_id(service_id: str) -> Optional[Dict[str, Any]]:
    """
    Obtiene informaci√≥n completa de un servicio por su ID.
    """
    try:
        result = supabase_client.table('services').select('*').eq('id', service_id).execute()
        
        if result.data:
            return result.data[0]
        return None
        
    except Exception as e:
        print(f"‚ùå Error obteniendo servicio {service_id}: {e}")
        return None



# --- Modelos de Respuesta ---

class KnowledgeSearchResult(BaseModel):
    """Modelo para el resultado de la b√∫squeda de conocimiento."""
    # Para servicios
    service_id: Optional[str] = Field(default=None, description="El ID √∫nico del servicio encontrado.")
    service_name: Optional[str] = Field(default=None, description="Nombre del servicio encontrado.")
    requires_assessment: Optional[bool] = Field(default=None, description="Si el servicio requiere valoraci√≥n previa.")
    
    # Para informaci√≥n general (archivos)
    information_found: Optional[str] = Field(default=None, description="Informaci√≥n espec√≠fica encontrada (ubicaci√≥n, horarios, contacto, etc.)")
    source_type: Optional[str] = Field(default=None, description="Tipo de fuente: 'service' o 'file'")
    category: Optional[str] = Field(default=None, description="Categor√≠a del archivo si es de tipo 'file'")
    
    # Para casos especiales
    clarification_message: Optional[str] = Field(default=None, description="Mensaje para pedir aclaraci√≥n al usuario si la b√∫squeda es ambigua o no arroja resultados.")



class UserFactsResult(BaseModel):
    """Modelo para el resultado de la b√∫squeda de hechos del usuario."""
    facts_found: List[str] = Field(default_factory=list, description="Lista de hechos encontrados sobre el usuario.")
    summary: str = Field(description="Resumen de los hechos encontrados.")

class UserSessionsResult(BaseModel):
    """Modelo para el resultado de la b√∫squeda de conversaciones pasadas."""
    conversations_found: List[str] = Field(default_factory=list, description="Lista de fragmentos de conversaciones relevantes.")
    summary: str = Field(description="Resumen de las conversaciones encontradas.")

class UserInsightsResult(BaseModel):
    """Modelo para el resultado de la b√∫squeda de insights del usuario."""
    insights_found: List[str] = Field(default_factory=list, description="Lista de insights/res√∫menes encontrados.")
    summary: str = Field(description="Resumen de los insights encontrados.")

# --- Definici√≥n del Agente de Conocimiento ---
knowledge_agent = Agent[GlobalState](
    'openai:gpt-4o', 
    deps_type=GlobalState,
    system_prompt="""
    Eres un asistente experto en la oferta de servicios de un centro de est√©tica.
    Tu trabajo es ayudar al usuario a encontrar y seleccionar el servicio que desea, utilizando tanto la informaci√≥n actual como el historial del usuario.

    HERRAMIENTAS DISPONIBLES:
    
    1. B√öSQUEDA DE INFORMACI√ìN:
       - 'knowledge_search': Busca servicios Y informaci√≥n general usando IA sem√°ntica
       - NO necesitas palabras exactas: busca por significado e intenci√≥n
       - Encuentra autom√°ticamente: ubicaci√≥n, horarios, contacto, FAQ, pol√≠ticas, promociones, etc.
    
    2. B√öSQUEDA DE HISTORIAL DEL USUARIO (√∫salas cuando sea relevante):
       - 'search_user_facts': Busca hechos espec√≠ficos (servicios previos, preferencias, alergias, etc.)
       - 'search_user_conversations': Busca conversaciones pasadas (recomendaciones, quejas, etc.)
       - 'search_user_insights': Busca patrones de comportamiento del usuario
    
    FLUJO DE TRABAJO:
    
    1. EVAL√öA LA CONSULTA: ¬øEl usuario menciona algo del pasado, historial, o "antes"?
       - SI: Usa herramientas de b√∫squeda de historial primero
       - NO: Procede con b√∫squeda de servicios
    
    2. B√öSQUEDA DE INFORMACI√ìN:
       - Usa 'knowledge_search' para encontrar servicios O informaci√≥n general
       - Para servicios: incluye service_id, nombre y si requiere valoraci√≥n
       - Para info general: incluye contenido directo (ubicaci√≥n, horarios, etc.)
       - Si necesitas aclaraci√≥n, devuelve el mensaje y termina
    
    3. PERSONALIZACI√ìN CON HISTORIAL:
       - Si es relevante, busca informaci√≥n previa del usuario
       - Combina la informaci√≥n actual con el historial para dar respuestas personalizadas
    
    EJEMPLOS DE USO:
    
    INFORMACI√ìN GENERAL (b√∫squeda sem√°ntica inteligente):
    - "¬øD√≥nde quedan?" / "direcci√≥n" / "ubicaci√≥n" ‚Üí Encuentra info de ubicaci√≥n
    - "¬øA qu√© hora abren?" / "horarios" / "cu√°ndo atienden?" ‚Üí Encuentra horarios
    - "¬øTel√©fono?" / "contacto" / "WhatsApp" ‚Üí Encuentra info de contacto
    - "¬øOfertas?" / "descuentos" / "promociones" ‚Üí Encuentra promociones
    - "¬øDudas frecuentes?" / "FAQ" / "preguntas" ‚Üí Encuentra FAQ
    - "¬øPol√≠ticas?" / "reglas" / "t√©rminos" ‚Üí Encuentra pol√≠ticas
    
    SERVICIOS:
    - "Quiero algo para rejuvenecer" ‚Üí Busca servicios
    - "¬øCu√°nto cuesta el hidrofacial?" ‚Üí Busca servicio espec√≠fico
    
    HISTORIAL DEL USUARIO:
    - "¬øQu√© servicios me recomendaste antes?" ‚Üí search_user_conversations
    - "¬øCu√°les fueron mis servicios favoritos?" ‚Üí search_user_facts
    - "¬øTuve alg√∫n problema?" ‚Üí search_user_facts
    - "¬øHe venido antes por problemas de acn√©?"
    
    IMPORTANTE: No respondas directamente al usuario, solo ejecuta las herramientas necesarias y devuelve sus resultados estructurados.
    """
)

# --- Herramientas del Agente ---

@knowledge_agent.tool
async def knowledge_search(ctx: RunContext[GlobalState], query: str) -> KnowledgeSearchResult:
    """
    Busca cualquier informaci√≥n (servicios, ubicaci√≥n, horarios, contacto, etc.) usando b√∫squeda sem√°ntica.
    Si encuentra informaci√≥n relevante, la devuelve. Si no, ofrece escalaci√≥n a asesor.
    """
    state = ctx.deps
    organization_id = state.get("organization_id")
    
    if not organization_id:
        return KnowledgeSearchResult(clarification_message="Error: No se pudo identificar la organizaci√≥n.")
    
    print(f"üîç Buscando informaci√≥n para: '{query}' en organizaci√≥n {organization_id}")
    
    try:
        # Buscar con l√≠mite de 3 resultados m√°s relevantes
        matching_results = await search_knowledge_semantic(query, organization_id, limit=3)
        
        if not matching_results:
            return KnowledgeSearchResult(
                clarification_message=f"No encontr√© informaci√≥n espec√≠fica sobre '{query}'. ¬øTe gustar√≠a hablar con un asesor que pueda ayudarte mejor?"
            )
        
        # Tomar el resultado m√°s relevante (primero)
        best_result = matching_results[0]
        metadata = best_result.get('metadata', {})
        source_type = metadata.get('source_type')
        content = best_result.get('content', '')
        similarity = best_result.get('similarity', 0)
        
        print(f"‚úÖ Informaci√≥n encontrada: source_type={source_type}, similarity={similarity:.2f}")
        print(f"üìÑ Content preview: {content[:100]}...")
        
        if source_type == 'file':
            # Es informaci√≥n general (ubicaci√≥n, horarios, etc.)
            return KnowledgeSearchResult(
                information_found=content,
                source_type='file',
                category=metadata.get('category', 'general')
            )
        
        elif source_type == 'service':
            # Es informaci√≥n de un servicio
            service_id = metadata.get('service_id')
            service_data = await get_service_by_id(service_id)
            return KnowledgeSearchResult(
                service_id=service_id,
                service_name=service_data['name'] if service_data else None,
                requires_assessment=service_data['requiere_valoracion'] if service_data else None,
                source_type='service'
            )
        
        else:
            # Tipo de fuente desconocido, devolver contenido como informaci√≥n general
            return KnowledgeSearchResult(
                information_found=content,
                source_type='unknown'
            )
            
    except Exception as e:
        print(f"‚ùå Error en knowledge_search: {e}")
        return KnowledgeSearchResult(
            clarification_message="Hubo un problema al buscar informaci√≥n. ¬øTe gustar√≠a hablar con un asesor?"
        )


@knowledge_agent.tool
async def search_user_facts(ctx: RunContext[GlobalState], query: str) -> UserFactsResult:
    """
    Busca hechos espec√≠ficos sobre el usuario actual en su historial.
    √ötil para encontrar preferencias, servicios previos, problemas reportados, etc.
    
    Ejemplos de uso:
    - "servicios previos" 
    - "problemas de piel"
    - "preferencias de horarios"
    - "reacciones al√©rgicas"
    """
    state = ctx.deps
    print(f"üîç Buscando hechos del usuario para: '{query}'")
    
    if not state.get("chat_identity_id"):
        return UserFactsResult(
            facts_found=[],
            summary="No hay informaci√≥n del usuario disponible en esta sesi√≥n."
        )
    
    # Construir user_id como en main.py
    if state.get("contact_id"):
        user_id = f"contact_{state['contact_id']}"
    else:
        user_id = f"chat_{state['chat_identity_id']}"
    
    try:
        facts = await search_zep_facts(user_id=user_id, query=query, limit=5)
        
        if facts:
            summary = f"Encontr√© {len(facts)} hechos relevantes sobre '{query}'"
            print(f"‚úÖ {summary}")
            return UserFactsResult(facts_found=facts, summary=summary)
        else:
            summary = f"No encontr√© informaci√≥n espec√≠fica sobre '{query}' en el historial del usuario."
            print(f"‚ùå {summary}")
            return UserFactsResult(facts_found=[], summary=summary)
            
    except Exception as e:
        print(f"‚ùå Error buscando hechos: {e}")
        return UserFactsResult(
            facts_found=[],
            summary="Error al buscar en el historial del usuario."
        )

@knowledge_agent.tool
async def search_user_conversations(ctx: RunContext[GlobalState], query: str) -> UserSessionsResult:
    """
    Busca conversaciones pasadas del usuario que contengan informaci√≥n espec√≠fica.
    √ötil para recordar discusiones previas, recomendaciones hechas, etc.
    
    Ejemplos de uso:
    - "citas canceladas"
    - "servicios recomendados"
    - "quejas o problemas"
    - "horarios preferidos"
    """
    state = ctx.deps
    print(f"üîç Buscando conversaciones del usuario para: '{query}'")
    
    if not state.get("chat_identity_id"):
        return UserSessionsResult(
            conversations_found=[],
            summary="No hay historial de conversaciones disponible en esta sesi√≥n."
        )
    
    # Construir user_id como en main.py
    if state.get("contact_id"):
        user_id = f"contact_{state['contact_id']}"
    else:
        user_id = f"chat_{state['chat_identity_id']}"
    
    try:
        conversations = await search_zep_sessions(user_id=user_id, query=query, limit=3)
        
        if conversations:
            summary = f"Encontr√© {len(conversations)} conversaciones relevantes sobre '{query}'"
            print(f"‚úÖ {summary}")
            return UserSessionsResult(conversations_found=conversations, summary=summary)
        else:
            summary = f"No encontr√© conversaciones previas sobre '{query}'."
            print(f"‚ùå {summary}")
            return UserSessionsResult(conversations_found=[], summary=summary)
            
    except Exception as e:
        print(f"‚ùå Error buscando conversaciones: {e}")
        return UserSessionsResult(
            conversations_found=[],
            summary="Error al buscar en el historial de conversaciones."
        )

@knowledge_agent.tool
async def search_user_insights(ctx: RunContext[GlobalState], query: str) -> UserInsightsResult:
    """
    Busca insights y res√∫menes sobre el comportamiento del usuario.
    √ötil para entender patrones, preferencias generales, perfil del cliente.
    
    Ejemplos de uso:
    - "perfil del cliente"
    - "comportamiento de compra"
    - "satisfacci√≥n con servicios"
    - "tendencias de uso"
    """
    state = ctx.deps
    print(f"üîç Buscando insights del usuario para: '{query}'")
    
    if not state.get("chat_identity_id"):
        return UserInsightsResult(
            insights_found=[],
            summary="No hay informaci√≥n de insights disponible en esta sesi√≥n."
        )
    
    # Construir user_id como en main.py
    if state.get("contact_id"):
        user_id = f"contact_{state['contact_id']}"
    else:
        user_id = f"chat_{state['chat_identity_id']}"
    
    try:
        insights = await search_zep_nodes(user_id=user_id, query=query, limit=3)
        
        if insights:
            summary = f"Encontr√© {len(insights)} insights relevantes sobre '{query}'"
            print(f"‚úÖ {summary}")
            return UserInsightsResult(insights_found=insights, summary=summary)
        else:
            summary = f"No encontr√© insights espec√≠ficos sobre '{query}'."
            print(f"‚ùå {summary}")
            return UserInsightsResult(insights_found=[], summary=summary)
            
    except Exception as e:
        print(f"‚ùå Error buscando insights: {e}")
        return UserInsightsResult(
            insights_found=[],
            summary="Error al buscar insights del usuario."
        )

# --- Funci√≥n de Entrada (Entrypoint) para el Grafo ---
async def run_knowledge_agent(state: GlobalState) -> Dict[str, Any]:
    """
    Punto de entrada para ejecutar el agente de conocimiento.
    Ahora incluye contexto de memoria de Zep.
    """
    print("--- Ejecutando Knowledge Agent ---")
    
    user_query = state['messages'][-1].content
    
    # Obtener contexto de memoria de Zep si hay chat_identity_id
    zep_context = ""
    if state.get("chat_identity_id"):
        thread_id = state['chat_identity_id']
        try:
            zep_context = await get_zep_memory_context(thread_id, min_rating=0.0)
        except Exception as e:
            print(f"‚ùå Error obteniendo contexto de Zep thread {thread_id}: {e}")
            zep_context = ""
    
    # Construir query enriquecido con contexto de Zep
    enhanced_query = user_query
    if zep_context:
        enhanced_query = f"Contexto del usuario: {zep_context}\n\nConsulta actual: {user_query}"
    
    result = await knowledge_agent.run(enhanced_query, deps=state)
    
    # El resultado del agente puede ser de varios tipos, lo procesamos
    tool_output = result.output

    if isinstance(tool_output, KnowledgeSearchResult):
        if tool_output.clarification_message:
            # Si la herramienta devuelve un mensaje de clarificaci√≥n (incluso si fall√≥),
            # lo tratamos como la respuesta final de este turno para romper el bucle.
            return {
                "messages": [("ai", tool_output.clarification_message)]
            }
        elif tool_output.service_id:
            # Si se encontr√≥ un servicio, incluir informaci√≥n de valoraci√≥n si est√° disponible
            result_data = {"service_id": tool_output.service_id}
            if tool_output.requires_assessment is not None:
                result_data["requires_assessment"] = tool_output.requires_assessment
            if tool_output.service_name:
                result_data["service_name"] = tool_output.service_name
            return result_data
        elif tool_output.information_found:
            # Si se encontr√≥ informaci√≥n general (archivos), devolverla directamente
            return {
                "messages": [("ai", tool_output.information_found)],
                "next_agent": "terminate"  # Indicar que la tarea se complet√≥
            }
    
    elif isinstance(tool_output, UserFactsResult):
        if tool_output.facts_found:
            facts_text = "\n".join([f"- {fact}" for fact in tool_output.facts_found])
            response_message = f"{tool_output.summary}\n\n{facts_text}"
            return {"messages": [("ai", response_message)]}
        else:
            # Si no se encuentran hechos, no se devuelve ning√∫n mensaje para evitar bucles.
            return {}
    
    elif isinstance(tool_output, UserSessionsResult):
        if tool_output.conversations_found:
            conversations_text = "\n".join([f"- {conv}" for conv in tool_output.conversations_found])
            response_message = f"{tool_output.summary}\n\n{conversations_text}"
            return {"messages": [("ai", response_message)]}
        else:
            return {}

    elif isinstance(tool_output, UserInsightsResult):
        if tool_output.insights_found:
            insights_text = "\n".join([f"- {insight}" for insight in tool_output.insights_found])
            response_message = f"{tool_output.summary}\n\n{insights_text}"
            return {"messages": [("ai", response_message)]}
        else:
            return {}

    # Si el resultado es un string directo (respuesta del LLM)
    elif isinstance(tool_output, str):
        return {
            "messages": [("ai", tool_output)]
        }

    # Caso por defecto o si la salida no es lo que esperamos
    return {
        "messages": [("ai", "No estoy seguro de c√≥mo proceder. ¬øPuedes reformular tu pregunta?")]
    }