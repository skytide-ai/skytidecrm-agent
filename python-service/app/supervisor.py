from typing import Literal, Optional
from pydantic import BaseModel, Field
from pydantic_ai import Agent
from langgraph.types import Command
from langchain_core.messages import AIMessage, HumanMessage
import json

from .state import GlobalState
from .agents.knowledge_agent import KnowledgeSearchResult
from .zep import get_zep_memory_context

AGENT_NAMES = ("KnowledgeAgent", "AppointmentAgent", "EscalationAgent")
TERMINATE = "__end__"

class Router(BaseModel):
    """Define la ruta a seguir o la respuesta directa."""
    next_agent: Literal[*AGENT_NAMES, "Formatter", TERMINATE] = Field(description="El nombre del siguiente agente a invocar.")
    response: Optional[str] = Field(default=None, description="La respuesta conversacional si next_agent es '__end__'.")

async def supervisor_node(state: GlobalState) -> Command:
    """Nodo supervisor que enruta de forma estructurada."""
    print("--- Supervisor Estructurado ---")
    latest_user_message = next((m for m in reversed(state["messages"]) if isinstance(m, HumanMessage)), None)
    if not latest_user_message:
        return Command(goto=TERMINATE)

    # 1. Obtener memoria de Zep (largo plazo)
    zep_context = ""
    if state.get("chat_identity_id"):
        try:
            zep_context = await get_zep_memory_context(state["chat_identity_id"], min_rating=0.0)
            print(f"üß† Supervisor usando Contexto Zep: {zep_context}")
        except Exception as e:
            print(f"‚ùå Error obteniendo contexto de Zep en Supervisor: {e}")
            zep_context = ""
    
    # 2. Obtener historial de sesi√≥n (corto plazo), limitado a los √∫ltimos 10 mensajes
    messages = state.get("messages", [])
    history = "\n".join(
        [f"- {m.type}: {m.content}" for m in messages[-10:]]
    )

    # 3. Construcci√≥n del prompt para el supervisor
    base_prompt = f"""
    Eres un supervisor de IA experto en enrutamiento. Tu misi√≥n es analizar el contexto completo (memoria a largo plazo y conversaci√≥n reciente) para decidir el siguiente paso.

    **MEMORIA A LARGO PLAZO (Zep) - Hechos y Res√∫menes Clave:**
    {zep_context if zep_context else "Sin memoria a largo plazo."}
    
    **HISTORIAL DE CONVERSACI√ìN RECIENTE:**
    {history}
    
    **√öLTIMO MENSAJE DEL USUARIO:** "{latest_user_message.content}"
    
    Agentes Disponibles: {', '.join(AGENT_NAMES)}.
    """

    context_prompt = ""
    if state.get("available_slots"):
        print("-> CONTEXTO: Agendamiento (Slots Disponibles)")
        context_prompt = """
        **¬°ATENCI√ìN! CONTEXTO DE AGENDAMIENTO (FASE 1 - SELECCI√ìN):**
        - Acabas de presentar horarios. La prioridad es manejar la selecci√≥n del usuario.
        - **Prioridad 1 (Selecci√≥n):** Si el usuario elige un horario (ej: "a las 10 am"), enruta a `AppointmentAgent`.
        - **Prioridad 2 (Ajuste):** Si pide OTRA FECHA/HORA (ej: "¬øy ma√±ana?"), enruta a `AppointmentAgent`.
        - **Prioridad 3 (Cambio de Tema):** Si pregunta por OTRO SERVICIO o tema, enruta a `KnowledgeAgent`.
        """
    elif state.get("service_id"):
        print("-> CONTEXTO: Agendamiento (Servicio Seleccionado)")
        context_prompt = f"""
        **¬°ATENCI√ìN! CONTEXTO DE AGENDAMIENTO (FASE 0 - RECOLECCI√ìN DE FECHA):**
        - El usuario ya seleccion√≥ o se le acaba de presentar el servicio '{state.get('service_name', 'desconocido')}' (ID: {state.get('service_id')}) y quiere agendar.
        - **Prioridad 0 (Confirmaci√≥n):** Si el usuario simplemente confirma que quiere ese servicio (ej: "s√≠", "ese est√° bien", "perfecto"), enruta a `AppointmentAgent` para que pida la fecha.
        - **Prioridad 1 (Dar Fecha):** Si el usuario proporciona una fecha o referencia temporal (ej: "para ma√±ana", "el lunes"), enruta a `AppointmentAgent` para que busque disponibilidad.
        - **Prioridad 2 (Pregunta sobre Servicio Actual):** Si el usuario pregunta algo m√°s sobre el servicio actual (ej: "¬øcu√°nto dura?", "y el precio?"), enruta a `KnowledgeAgent`. La b√∫squeda se filtrar√° autom√°ticamente.
        - **Prioridad 3 (Cambio de Servicio):** Si pregunta por un servicio DIFERENTE, enruta a `KnowledgeAgent`.
        """
    else:
        print("-> CONTEXTO: General (Sin Selecci√≥n)")

    routing_rules = """
    **Reglas Generales de Enrutamiento (si no hay contexto espec√≠fico):**
    - **Consulta de Informaci√≥n:** Si el usuario pregunta por precios, horarios, servicios, etc., enruta a `KnowledgeAgent`.
    - **Intenci√≥n de Agendar:** Si el usuario quiere reservar o agendar (y no hay un contexto de agendamiento activo), enruta a `AppointmentAgent`.
    - **Petici√≥n de Ayuda Humana:** Si el usuario est√° frustrado o pide hablar con una persona, enruta a `EscalationAgent`.
    - **Conversaci√≥n Casual:** Si es un saludo, despedida o agradecimiento, responde amablemente y pregunta c√≥mo puedes ayudar, y enruta a `__end__`.
    
    Siempre debes devolver un objeto `Router` completo.
    """
    
    system_prompt = f"{base_prompt}{context_prompt}{routing_rules}"
    
    supervisor_agent = Agent('openai:gpt-4o', output_type=Router, system_prompt=system_prompt)
    
    result = await supervisor_agent.run(latest_user_message.content, deps=state)
    router_output: Router = result.output

    if router_output.next_agent == TERMINATE:
        ai_message = AIMessage(content=router_output.response or "¬°Claro! ¬øEn qu√© m√°s puedo ayudarte?", name="Supervisor")
        return Command(update={"messages": state["messages"] + [ai_message]}, goto=TERMINATE)
    
    return Command(goto=router_output.next_agent)

async def response_formatter_node(state: GlobalState) -> Command:
    """Nodo que formatea la salida de datos crudos en una respuesta conversacional."""
    print("--- Formateador de Respuestas (Con Logs) ---")
    
    raw_result = state.get("knowledge_result")
    
    print("\n--- DEBUG Formatter ---")
    print(f"Tipo de `knowledge_result` recibido: {type(raw_result)}")
    print(f"Contenido de `knowledge_result`:\n{json.dumps(raw_result, indent=2) if isinstance(raw_result, dict) else raw_result}")
    
    knowledge_result = None
    if isinstance(raw_result, dict):
        knowledge_result = KnowledgeSearchResult(**raw_result)
    elif isinstance(raw_result, KnowledgeSearchResult):
        knowledge_result = raw_result

    # Ahora la l√≥gica de validaci√≥n es m√°s robusta
    if not knowledge_result:
        print("Resultado: `knowledge_result` est√° vac√≠o o no es v√°lido.")
        response = "Lo siento, no pude procesar tu solicitud. ¬øPrefieres hablar con un asesor?"
        ai_message = AIMessage(content=response, name="Formatter")
        return Command(update={"messages": state["messages"] + [ai_message]}, goto=TERMINATE)

    if knowledge_result.clarification_message:
        print(f"Resultado: Se encontr√≥ mensaje de clarificaci√≥n: '{knowledge_result.clarification_message}'")
        response = f"Lo siento, tuve un problema. {knowledge_result.clarification_message} ¬øTe gustar√≠a que te conecte con un asesor?"
        ai_message = AIMessage(content=response, name="Formatter")
        return Command(update={"messages": state["messages"] + [ai_message]}, goto=TERMINATE)

    if not knowledge_result.raw_information:
        print("Resultado: No se encontr√≥ `raw_information` para formatear.")
        response = "Lo siento, no pude procesar tu solicitud. ¬øPodr√≠as intentarlo de nuevo o prefieres hablar con un asesor?"
        ai_message = AIMessage(content=response, name="Formatter")
        return Command(update={"messages": state["messages"] + [ai_message]}, goto=TERMINATE)
    
    print(f"Resultado: Se encontr√≥ `raw_information` de {len(knowledge_result.raw_information)} caracteres.")
    print("---------------------------\n")

    latest_user_message = next((m for m in reversed(state["messages"]) if isinstance(m, HumanMessage)), None)
    user_query = latest_user_message.content if latest_user_message else ""

    service_context = f"Estamos hablando del servicio: '{knowledge_result.service_name}'." if knowledge_result.service_name else "No hay un servicio espec√≠fico en contexto."

    prompt = f"""
    Eres un asistente de IA experto en crear respuestas naturales y contextualmente relevantes. Tu tarea es responder a la pregunta del usuario de forma precisa.

    **CONTEXTO DISPONIBLE:**
    - **Pregunta del Usuario:** "{user_query}"
    - **Contexto del Servicio:** {service_context}
    - **Informaci√≥n Encontrada:**
      ---
      {knowledge_result.raw_information}
      ---

    **TUS INSTRUCCIONES:**
    1.  Usa la "Informaci√≥n Encontrada" para responder a la "Pregunta del Usuario".
    2.  Si el "Contexto del Servicio" est√° disponible, √öSALO para que tu respuesta suene m√°s natural. Por ejemplo, en lugar de decir "Las contraindicaciones son...", di "Las contraindicaciones para el servicio de {knowledge_result.service_name} son...".
    3.  S√© directo, amigable y usa emojis üòä. No resumas toda la informaci√≥n, solo responde la pregunta.

    **Ejemplo de respuesta ideal:**
    "¬°Claro! Las contraindicaciones para el servicio de Limpieza Facial Profunda son acn√© activo o tener la piel quemada por el sol ‚òÄÔ∏è."
    """

    formatter_agent = Agent('openai:gpt-4o', system_prompt=prompt)
    result = await formatter_agent.run("") 
    
    formatted_response = str(result.data)
    ai_message = AIMessage(content=formatted_response, name="Formatter")
    
    update_data = {"messages": state["messages"] + [ai_message]}
    if knowledge_result.service_id:
        update_data["service_id"] = str(knowledge_result.service_id)
    if knowledge_result.service_name:
        update_data["service_name"] = knowledge_result.service_name
        
    return Command(update=update_data, goto=TERMINATE)
