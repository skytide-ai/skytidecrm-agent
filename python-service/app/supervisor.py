from typing import Literal
from pydantic_ai import Agent
from langgraph.types import Command
from langgraph.graph import END
from langchain_core.messages import AIMessage, HumanMessage, trim_messages

# Importamos el estado global y funciones de Zep
from .state import GlobalState
from .zep import get_zep_memory_context

# --- Cliente Pydantic AI ---
# ğŸ§  Supervisor usa Pydantic AI en lugar de cliente OpenAI directo

# 1. Definimos los nombres de nuestros agentes
AGENT_NAMES = ("KnowledgeAgent", "AppointmentAgent", "EscalationAgent")
TERMINATE = "terminate"

# 2. Definimos el esquema de salida estructurada para el supervisor
# ğŸ§  SUPERVISOR SEMÃNTICO: Sin modelos estructurados, usa comprensiÃ³n natural del LLM

# 3. Creamos la funciÃ³n del nodo supervisor que se usarÃ¡ en el grafo
async def supervisor_node(state: GlobalState) -> Command[Literal[*AGENT_NAMES, "__end__"]]:
    """
    Supervisor inteligente con anÃ¡lisis contextual avanzado.
    Usa context-aware decision making para routing inteligente.
    """
    print("--- Supervisor Inteligente ---")
    
    # --- 1. EXTRAER CONTEXTO COMPLETO ---
    latest_user_message = next((m for m in reversed(state["messages"]) if isinstance(m, HumanMessage)), None)
    latest_ai_message = next((m for m in reversed(state["messages"]) if isinstance(m, AIMessage)), None)

    if not latest_user_message:
        print("âš ï¸ No se encontrÃ³ un mensaje de usuario para procesar. Terminando.")
        return Command(goto="__end__")
    
    # --- 2. ANÃLISIS INTELIGENTE DE CONTEXTO ---
    current_service_id = state.get('service_id')
    current_service_name = state.get('service_name')
    user_query = latest_user_message.content
    
    print(f"ğŸ§  CONTEXTO ACTUAL:")
    print(f"   - service_id: {current_service_id}")
    print(f"   - service_name: {current_service_name}")
    print(f"   - Usuario dice: '{user_query}'")
    
    # --- 3. DETECCIÃ“N DE FLUJO COMPLETADO ---
    # Si hay una respuesta AI mÃ¡s reciente que el mensaje del usuario, la conversaciÃ³n estÃ¡ completa
    if (latest_ai_message and 
        latest_user_message and 
        state["messages"].index(latest_ai_message) > state["messages"].index(latest_user_message)):
        
        print("âœ… ConversaciÃ³n completada por un agente â†’ Terminando")
        return Command(goto="__end__")

    # --- 2. Preparar el contexto para el LLM ---
    history_messages = state["messages"][:-1]
    history_str = "\n".join([f"{msg.__class__.__name__}: {msg.content}" for msg in history_messages])
    
    zep_context = ""
    if state.get("chat_identity_id"):
        thread_id = state['chat_identity_id']
        try:
            zep_context = await get_zep_memory_context(thread_id)
            if zep_context:
                print(f"ğŸ§  Contexto Zep para thread {thread_id} encontrado.")
        except Exception as e:
            print(f"âš ï¸ No se pudo obtener contexto de Zep para thread {thread_id}. Error: {e}")

    # --- 3. Construir el Prompt Inteligente para el Supervisor ---
    system_prompt = f"""ğŸ§  SUPERVISOR INTELIGENTE CON ANÃLISIS CONTEXTUAL AVANZADO

**TU MISIÃ“N:** Analizar la intenciÃ³n REAL del usuario y tomar la decisiÃ³n MÃS INTELIGENTE sobre el prÃ³ximo paso.

**CONTEXTO ACTUAL:**
- Estado del servicio: {"ğŸ¯ SERVICIO IDENTIFICADO (" + str(current_service_name) + ")" if current_service_id else "âŒ SIN SERVICIO"}
- Service ID: {current_service_id or "None"}

**HISTORIAL DE LA CONVERSACIÃ“N:**
{history_str}

**MEMORIA DEL USUARIO:**
{zep_context or "Sin informaciÃ³n previa"}

**ğŸ¯ ANÃLISIS INTELIGENTE DE INTENCIONES:**

**ğŸ§  ANÃLISIS SEMÃNTICO INTELIGENTE - SIN KEYWORDS**

TU TAREA: Analiza la INTENCIÃ“N REAL del usuario usando comprensiÃ³n semÃ¡ntica avanzada, NO patrones de palabras especÃ­ficas.

**TIPOS DE INTENCIÃ“N:**

1. **CONVERSACIÃ“N SOCIAL**: Saludos, despedidas, cortesÃ­a, preguntas personales sobre el asistente
   â†’ `terminate` (responde amablemente)

2. **INFORMACIÃ“N DEL NEGOCIO**: Cualquier pregunta sobre servicios, productos, precios, ubicaciÃ³n, horarios, contacto
   â†’ `KnowledgeAgent` (buscar informaciÃ³n real)

3. **INTENCIÃ“N DE AGENDAR**: Usuario quiere reservar/programar algo
   - Si YA hay service_id: â†’ `AppointmentAgent`
   - Si NO hay service_id: â†’ `KnowledgeAgent` (identificar servicio primero)

4. **ESCALACIÃ“N HUMANA**: Usuario quiere hablar con una persona real
   â†’ `EscalationAgent`

**ğŸ§  ANÃLISIS SEMÃNTICO AVANZADO:**
- Entiende SINÃ“NIMOS y VARIACIONES naturales del lenguaje
- Analiza CONTEXTO y INTENCIÃ“N, no solo palabras exactas
- Distingue entre preguntas sobre TI (negocio) vs MÃ (asistente personal)
- Reconoce diferentes formas de expresar la misma intenciÃ³n

**EJEMPLOS DE COMPRENSIÃ“N SEMÃNTICA:**
- "Â¿DÃ³nde quedan?" = "Â¿CuÃ¡l es la direcciÃ³n?" = "Â¿UbicaciÃ³n?" â†’ INFORMACIÃ“N DEL NEGOCIO
- "Quiero cita" = "Necesito reservar" = "Me gustarÃ­a agendar" â†’ INTENCIÃ“N DE AGENDAR
- "Â¿CÃ³mo estÃ¡s?" = "Â¿Todo bien?" = "Â¿QuÃ© tal?" â†’ CONVERSACIÃ“N SOCIAL
- "Necesito ayuda" = "Quiero hablar con alguien" â†’ ESCALACIÃ“N HUMANA

**PRINCIPIO CLAVE:**
- USA tu comprensiÃ³n natural del lenguaje
- NO busques palabras especÃ­ficas, ENTIENDE la intenciÃ³n
- Reconoce variaciones, modismos y sinÃ³nimos automÃ¡ticamente
- Si hay duda entre informaciÃ³n vs social â†’ prefiere informaciÃ³n (buscar en base de datos)

**ğŸš¨ NUNCA INVENTES INFORMACIÃ“N DEL NEGOCIO:**
- Para cualquier dato del negocio â†’ responde "KnowledgeAgent"
- Para conversaciÃ³n social â†’ responde directamente como un asistente amigable

**FORMATO DE RESPUESTA:**
- Si es consulta informativa: responde "KnowledgeAgent - [descripciÃ³n de la consulta]"
- Si es intenciÃ³n de agendar: responde "AppointmentAgent - [descripciÃ³n de la intenciÃ³n]"
- Si es escalaciÃ³n: responde "EscalationAgent - [razÃ³n]"
- Si es conversaciÃ³n social: responde directamente con un saludo amigable (ej: "Â¡Hola! Â¿En quÃ© puedo ayudarte hoy? ğŸ˜Š")"""
    
    user_input_for_llm = f"""
    **MENSAJE DEL USUARIO A PROCESAR:**
    "{latest_user_message.content}"
    """

    # --- 4. Invocar el LLM (Supervisor) ---
    supervisor_agent = Agent[GlobalState](
        'openai:gpt-4o',
        deps_type=GlobalState,
        system_prompt=system_prompt
    )
    
    print(f"ğŸ” Invocando supervisor semÃ¡ntico para: '{latest_user_message.content}'")
    result = await supervisor_agent.run(user_input_for_llm, deps=state)
    
    # El LLM ahora responde usando anÃ¡lisis semÃ¡ntico natural (devuelve str directamente)
    response_text = result.data
    
    print(f"ğŸ§  Supervisor analizÃ³: '{response_text[:100]}...'")
    
    # AnÃ¡lisis inteligente de la respuesta del LLM
    response_lower = response_text.lower()
    
    # DetecciÃ³n semÃ¡ntica avanzada basada en la respuesta del LLM
    if "knowledgeagent" in response_lower or "knowledge_agent" in response_lower or "buscar informaciÃ³n" in response_lower:
        print("ğŸ“‹ AnÃ¡lisis semÃ¡ntico: Consulta informativa â†’ KnowledgeAgent")
        return Command(goto="KnowledgeAgent")
    elif "appointmentagent" in response_lower or "appointment_agent" in response_lower:
        print("ğŸ“… AnÃ¡lisis semÃ¡ntico: IntenciÃ³n de agendar â†’ AppointmentAgent") 
        return Command(goto="AppointmentAgent")
    elif "escalationagent" in response_lower or "escalation_agent" in response_lower:
        print("ğŸ¤ AnÃ¡lisis semÃ¡ntico: EscalaciÃ³n â†’ EscalationAgent")
        return Command(goto="EscalationAgent")
    elif "terminate" in response_lower or any(social in response_lower for social in ["hola", "bien", "gracias", "adiÃ³s"]):
        print("ğŸ’¬ AnÃ¡lisis semÃ¡ntico: ConversaciÃ³n social â†’ Respuesta directa")
        ai_message = AIMessage(content=response_text, name="Supervisor")
        current_messages = state.get("messages", [])
        return Command(
            update={"messages": current_messages + [ai_message]},
            goto="__end__"
        )
    else:
        # Fallback inteligente: si hay duda, buscar informaciÃ³n
        print("â“ AnÃ¡lisis semÃ¡ntico ambiguo â†’ KnowledgeAgent (fallback inteligente)")
        return Command(goto="KnowledgeAgent")
